{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OEseycp0Qj-i",
        "outputId": "24cdb2fc-136e-408a-fce4-12574a6b804e"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3zrlYM0AQ1df"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "\n",
        "generation_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a twitter techie influencer assistant tasked with writing excellent twitter posts.\"\n",
        "            \" Generate the best twitter post possible for the user's request.\"\n",
        "            \" If the user provides critique, respond with a revised version of your previous attempts.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "reflection_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a viral twitter influencer grading a tweet. Generate critique and recommendations for the user's tweet.\"\n",
        "            \"Always provide detailed recommendations, including requests for length, virality, style, etc.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "generation_chain = generation_prompt | llm\n",
        "reflection_chain = reflection_prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZLEq9E8_RsUI",
        "outputId": "e87f4cd3-0f82-4f33-ac4f-0c7fd0987d56"
      },
      "outputs": [],
      "source": [
        "!pip install grandalf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n7ayZCfRk-V",
        "outputId": "66b24462-54cf-4b53-bee7-f6bf0139e728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__(<p>__start__</p>)\n",
            "\tgenerate(generate)\n",
            "\treflect(reflect)\n",
            "\t__end__(<p>__end__</p>)\n",
            "\t__start__ --> generate;\n",
            "\tgenerate --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n",
            "+-----------+  \n",
            "| __start__ |  \n",
            "+-----------+  \n",
            "      *        \n",
            "      *        \n",
            "      *        \n",
            "+----------+   \n",
            "| generate |   \n",
            "+----------+   \n",
            "      *        \n",
            "      *        \n",
            "      *        \n",
            " +---------+   \n",
            " | __end__ |   \n",
            " +---------+   \n",
            "[HumanMessage(content='AI Agents taking over content creation', additional_kwargs={}, response_metadata={}, id='f374845d-06db-49f2-85d5-69bcf79bae53'), AIMessage(content=\"**Option 1 (Focus on the future):**\\n\\nAI agents are changing the content creation game! ðŸš€  From generating initial drafts to optimizing SEO, the possibilities are endless.  What are your thoughts on the future of AI in content? #AI #ContentCreation #ArtificialIntelligence #FutureofWork\\n\\n\\n**Option 2 (Focus on efficiency):**\\n\\nContent creation just got a whole lot faster!  AI agents are streamlining workflows & boosting productivity.  Less time spent on busywork, more time on strategy.  Are you using AI to enhance your content game?  #AIContent #Productivity #Efficiency #ContentMarketing\\n\\n\\n**Option 3 (Focus on a question to spark engagement):**\\n\\nWill AI agents replace human content creators? ðŸ¤”  I don't think so!  Instead, I see them as powerful tools to amplify human creativity.  What's your take? #AIvsHuman #ContentCreators #ArtificialIntelligence #FutureofContent\\n\\n\\n**Option 4 (More playful and concise):**\\n\\nRobots writing blog posts?  It's happening! ðŸ¤–  AI agents are revolutionizing content creation.  What's the most creative thing you've seen AI do? #AI #Content #Robots #Creativity\\n\\n\\nChoose the option that best suits your overall Twitter style and audience.  Let me know what you think, and we can refine it further!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run-545d5b33-185f-41ec-8dbc-6d2cfc071ac4-0', usage_metadata={'input_tokens': 50, 'output_tokens': 283, 'total_tokens': 333, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='**Critique of the original tweet:**\\n\\nThe original tweet, \"AI Agents taking over content creation,\" is too short and lacks engagement.  It\\'s a statement rather than a conversation starter.  It also doesn\\'t use relevant hashtags to increase visibility.  To make it more effective, you need to:\\n\\n* **Expand on the topic:**  Instead of just stating a fact, provide context, an opinion, or a question to encourage interaction.\\n* **Use relevant hashtags:**  Hashtags are crucial for discoverability on Twitter.  Research popular and relevant hashtags related to AI, content creation, and technology.\\n* **Consider adding a visual:**  A relevant image or video can significantly improve engagement.\\n* **Keep it concise but engaging:**  Aim for a tweet length that is easy to read and understand, but still provides enough information to spark interest.\\n\\n**Recommendations for improvement:**\\n\\n* **Length:** Aim for 100-120 characters to allow for hashtags and a compelling statement.\\n* **Style:**  Use a more engaging and conversational tone.  Ask questions, use emojis, or express a strong opinion.\\n* **Virality:**  Use relevant and trending hashtags, consider adding a visual element, and create content that is timely and topical.\\n* **Engagement:**  Ask a question to encourage responses and start a conversation.  Respond to replies to build community.\\n\\n\\nBy incorporating these recommendations, you can significantly increase the chances of your tweet going viral and engaging your audience.', additional_kwargs={}, response_metadata={}, id='10f29deb-fcb6-4138-b19b-3203c650ace3'), AIMessage(content=\"Okay, I've revised the tweet based on your excellent feedback. Here are a few options:\\n\\n\\n**Option 1 (Focus on collaboration):**\\n\\nAI agents aren't taking *over* content creation, they're boosting it! ðŸš€  Think superhuman teams: humans + AI collaborating for faster, better content.  What are your favorite AI writing tools? #AIContentCreation #AIWriting #ContentMarketing #HumanAI\\n\\n\\n**Option 2 (Provocative question):**\\n\\nIs AI the future of content creation? ðŸ¤”  Or just a powerful tool to supercharge human creativity? Let's discuss! #AI #ContentCreation #ArtificialIntelligence #FutureOfWork #Tech\\n\\n\\n**Option 3 (Focus on benefits with a call to action):**\\n\\nTired of writer's block? ðŸ˜© AI agents can help!  From generating ideas to optimizing your writing, explore the power of AI in content creation. What are your biggest content challenges?  #AItools #ContentMarketing #Productivity #WritersLife\\n\\n\\n**Option 4 (Short, punchy, and visual-friendly -  *requires image of AI writing tool or similar*):**\\n\\nAI + Content Creation = ðŸ”¥  The future is here! [Image/GIF]  #AI #Content #Tech #Productivity\\n\\n\\nThese options are more concise, engaging, and utilize relevant hashtags.  They also aim for a conversational tone and include questions to encourage interaction.  Option 4 especially benefits from a strong visual to enhance engagement. Remember to tailor the hashtags to trending topics for maximum reach.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run-24c427e7-e100-46fd-9911-16efbd882343-0', usage_metadata={'input_tokens': 642, 'output_tokens': 319, 'total_tokens': 961, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=\"I've also tried to incorporate the feedback about length, style, virality, and engagement.  Let me know what you think!\", additional_kwargs={}, response_metadata={}, id='e45edc6f-777a-4993-8114-449de9e07373'), AIMessage(content=\"Great!  I need to see your attempts to give you specific feedback. Please share the tweets you've written incorporating the feedback.  I'm ready to help polish them to perfection!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run-3d3d7619-4f81-494e-82de-5bc8f5524a80-0', usage_metadata={'input_tokens': 988, 'output_tokens': 40, 'total_tokens': 1028, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=\"Once you share them, I'll look at:\\n\\n* **Length:** Is it concise and impactful within the Twitter character limit?\\n* **Style:** Does it have a conversational and engaging tone?  Is the language clear and easy to understand?\\n* **Virality:** Are the hashtags relevant, popular, and well-chosen to maximize reach? Does it have the potential to resonate with a wide audience?\\n* **Engagement:** Does it pose a question, encourage interaction, or stimulate a response?  Does it invite further discussion?\\n\\nI'll provide detailed feedback on each aspect, suggesting improvements where necessary.  Let's make your tweets go viral!\", additional_kwargs={}, response_metadata={}, id='b1c241d0-5740-4c7c-b381-66a75629acce'), AIMessage(content=\"Okay, I understand.  I'm eager to see your tweet drafts!  I'll provide detailed feedback based on your criteria once you share them. Let's make those tweets shine!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run-fc157631-ce4a-494d-ae77-a5deea8f95df-0', usage_metadata={'input_tokens': 1163, 'output_tokens': 41, 'total_tokens': 1204, 'input_token_details': {'cache_read': 0}})]\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Sequence\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langgraph.graph import END, MessageGraph\n",
        "\n",
        "REFLECT = \"reflect\"\n",
        "GENERATE = \"generate\"\n",
        "graph = MessageGraph()\n",
        "\n",
        "def generate_node(state):\n",
        "    return generation_chain.invoke({\n",
        "        \"messages\": state\n",
        "    })\n",
        "\n",
        "\n",
        "def reflect_node(messages):\n",
        "    response = reflection_chain.invoke({\n",
        "        \"messages\": messages\n",
        "    })\n",
        "    return [HumanMessage(content=response.content)]\n",
        "\n",
        "\n",
        "graph.add_node(GENERATE, generate_node)\n",
        "graph.add_node(REFLECT, reflect_node)\n",
        "graph.set_entry_point(GENERATE)\n",
        "\n",
        "\n",
        "def should_continue(state):\n",
        "    if (len(state) > 6):\n",
        "        return END\n",
        "    return REFLECT\n",
        "\n",
        "\n",
        "graph.add_conditional_edges(GENERATE, should_continue)\n",
        "graph.add_edge(REFLECT, GENERATE)\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "print(app.get_graph().draw_mermaid())\n",
        "app.get_graph().print_ascii()\n",
        "\n",
        "response = app.invoke(HumanMessage(content=\"AI Agents taking over content creation\"))\n",
        "\n",
        "print(response)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
